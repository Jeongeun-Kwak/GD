{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "through-gazette",
   "metadata": {},
   "source": [
    "# tokenized 개수 검증"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "personalized-spray",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from konlpy.tag import Okt\n",
    "okt = Okt()\n",
    "tokenized_0 = []\n",
    "with open(os.getenv('HOME')+'/aiffel/weat/synopsis_SF.txt', 'r') as file:\n",
    "    while True:\n",
    "        line = file.readline()\n",
    "        if not line: break\n",
    "        words = okt.pos(line, stem=True, norm=True)\n",
    "        res = []\n",
    "        for w in words:\n",
    "            if w[1] in [\"Noun\"]:      # \"Adjective\", \"Verb\" 등을 포함할 수도 있습니다.\n",
    "                res.append(w[0])    # 명사일 때만 tokenized 에 저장하게 됩니다. \n",
    "        tokenized_0.append(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "interesting-richmond",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1023\n"
     ]
    }
   ],
   "source": [
    "print(len(tokenized_0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "changing-migration",
   "metadata": {},
   "outputs": [],
   "source": [
    "okt = Okt()\n",
    "tokenized_1 = []\n",
    "with open(os.getenv('HOME')+'/aiffel/weat/synopsis_family.txt', 'r') as file:\n",
    "    while True:\n",
    "        line = file.readline()\n",
    "        if not line: break\n",
    "        words = okt.pos(line, stem=True, norm=True)\n",
    "        res = []\n",
    "        for w in words:\n",
    "            if w[1] in [\"Noun\"]:      # \"Adjective\", \"Verb\" 등을 포함할 수도 있습니다.\n",
    "                res.append(w[0])    # 명사일 때만 tokenized 에 저장하게 됩니다. \n",
    "        tokenized_1.append(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "controlled-caribbean",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "422\n"
     ]
    }
   ],
   "source": [
    "print(len(tokenized_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "incorrect-karaoke",
   "metadata": {},
   "outputs": [],
   "source": [
    "okt = Okt()\n",
    "tokenized_2 = []\n",
    "with open(os.getenv('HOME')+'/aiffel/weat/synopsis_show.txt', 'r') as file:\n",
    "    while True:\n",
    "        line = file.readline()\n",
    "        if not line: break\n",
    "        words = okt.pos(line, stem=True, norm=True)\n",
    "        res = []\n",
    "        for w in words:\n",
    "            if w[1] in [\"Noun\"]:      # \"Adjective\", \"Verb\" 등을 포함할 수도 있습니다.\n",
    "                res.append(w[0])    # 명사일 때만 tokenized 에 저장하게 됩니다. \n",
    "        tokenized_2.append(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cross-fighter",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "346\n"
     ]
    }
   ],
   "source": [
    "print(len(tokenized_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "figured-performance",
   "metadata": {},
   "outputs": [],
   "source": [
    "okt = Okt()\n",
    "tokenized_3 = []\n",
    "with open(os.getenv('HOME')+'/aiffel/weat/synopsis_horror.txt', 'r') as file:\n",
    "    while True:\n",
    "        line = file.readline()\n",
    "        if not line: break\n",
    "        words = okt.pos(line, stem=True, norm=True)\n",
    "        res = []\n",
    "        for w in words:\n",
    "            if w[1] in [\"Noun\"]:      # \"Adjective\", \"Verb\" 등을 포함할 수도 있습니다.\n",
    "                res.append(w[0])    # 명사일 때만 tokenized 에 저장하게 됩니다. \n",
    "        tokenized_3.append(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "african-backing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3088\n"
     ]
    }
   ],
   "source": [
    "print(len(tokenized_3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "neither-palestinian",
   "metadata": {},
   "outputs": [],
   "source": [
    "okt = Okt()\n",
    "tokenized_4 = []\n",
    "with open(os.getenv('HOME')+'/aiffel/weat/synopsis_etc.txt', 'r') as file:\n",
    "    while True:\n",
    "        line = file.readline()\n",
    "        if not line: break\n",
    "        words = okt.pos(line, stem=True, norm=True)\n",
    "        res = []\n",
    "        for w in words:\n",
    "            if w[1] in [\"Noun\"]:      # \"Adjective\", \"Verb\" 등을 포함할 수도 있습니다.\n",
    "                res.append(w[0])    # 명사일 때만 tokenized 에 저장하게 됩니다. \n",
    "        tokenized_4.append(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "vulnerable-village",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3687\n"
     ]
    }
   ],
   "source": [
    "print(len(tokenized_4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "honey-realtor",
   "metadata": {},
   "outputs": [],
   "source": [
    "okt = Okt()\n",
    "tokenized_5 = []\n",
    "with open(os.getenv('HOME')+'/aiffel/weat/synopsis_documentary.txt', 'r') as file:\n",
    "    while True:\n",
    "        line = file.readline()\n",
    "        if not line: break\n",
    "        words = okt.pos(line, stem=True, norm=True)\n",
    "        res = []\n",
    "        for w in words:\n",
    "            if w[1] in [\"Noun\"]:      # \"Adjective\", \"Verb\" 등을 포함할 수도 있습니다.\n",
    "                res.append(w[0])    # 명사일 때만 tokenized 에 저장하게 됩니다. \n",
    "        tokenized_5.append(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "lasting-aurora",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7147\n"
     ]
    }
   ],
   "source": [
    "print(len(tokenized_5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "pending-integrity",
   "metadata": {},
   "outputs": [],
   "source": [
    "okt = Okt()\n",
    "tokenized_6 = []\n",
    "with open(os.getenv('HOME')+'/aiffel/weat/synopsis_drama.txt', 'r') as file:\n",
    "    while True:\n",
    "        line = file.readline()\n",
    "        if not line: break\n",
    "        words = okt.pos(line, stem=True, norm=True)\n",
    "        res = []\n",
    "        for w in words:\n",
    "            if w[1] in [\"Noun\"]:      # \"Adjective\", \"Verb\" 등을 포함할 수도 있습니다.\n",
    "                res.append(w[0])    # 명사일 때만 tokenized 에 저장하게 됩니다. \n",
    "        tokenized_6.append(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "gorgeous-bridges",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19229\n"
     ]
    }
   ],
   "source": [
    "print(len(tokenized_6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "immediate-sphere",
   "metadata": {},
   "outputs": [],
   "source": [
    "okt = Okt()\n",
    "tokenized_7 = []\n",
    "with open(os.getenv('HOME')+'/aiffel/weat/synopsis_romance.txt', 'r') as file:\n",
    "    while True:\n",
    "        line = file.readline()\n",
    "        if not line: break\n",
    "        words = okt.pos(line, stem=True, norm=True)\n",
    "        res = []\n",
    "        for w in words:\n",
    "            if w[1] in [\"Noun\"]:      # \"Adjective\", \"Verb\" 등을 포함할 수도 있습니다.\n",
    "                res.append(w[0])    # 명사일 때만 tokenized 에 저장하게 됩니다. \n",
    "        tokenized_7.append(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "significant-circulation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5776\n"
     ]
    }
   ],
   "source": [
    "print(len(tokenized_7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "arbitrary-constraint",
   "metadata": {},
   "outputs": [],
   "source": [
    "okt = Okt()\n",
    "tokenized_8 = []\n",
    "with open(os.getenv('HOME')+'/aiffel/weat/synopsis_musical.txt', 'r') as file:\n",
    "    while True:\n",
    "        line = file.readline()\n",
    "        if not line: break\n",
    "        words = okt.pos(line, stem=True, norm=True)\n",
    "        res = []\n",
    "        for w in words:\n",
    "            if w[1] in [\"Noun\"]:      # \"Adjective\", \"Verb\" 등을 포함할 수도 있습니다.\n",
    "                res.append(w[0])    # 명사일 때만 tokenized 에 저장하게 됩니다. \n",
    "        tokenized_8.append(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "regulation-collectible",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "170\n"
     ]
    }
   ],
   "source": [
    "print(len(tokenized_8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "visible-factor",
   "metadata": {},
   "outputs": [],
   "source": [
    "okt = Okt()\n",
    "tokenized_9 = []\n",
    "with open(os.getenv('HOME')+'/aiffel/weat/synopsis_mystery.txt', 'r') as file:\n",
    "    while True:\n",
    "        line = file.readline()\n",
    "        if not line: break\n",
    "        words = okt.pos(line, stem=True, norm=True)\n",
    "        res = []\n",
    "        for w in words:\n",
    "            if w[1] in [\"Noun\"]:      # \"Adjective\", \"Verb\" 등을 포함할 수도 있습니다.\n",
    "                res.append(w[0])    # 명사일 때만 tokenized 에 저장하게 됩니다. \n",
    "        tokenized_9.append(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "trying-experiment",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1078\n"
     ]
    }
   ],
   "source": [
    "print(len(tokenized_9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "incident-spotlight",
   "metadata": {},
   "outputs": [],
   "source": [
    "okt = Okt()\n",
    "tokenized_10 = []\n",
    "with open(os.getenv('HOME')+'/aiffel/weat/synopsis_crime.txt', 'r') as file:\n",
    "    while True:\n",
    "        line = file.readline()\n",
    "        if not line: break\n",
    "        words = okt.pos(line, stem=True, norm=True)\n",
    "        res = []\n",
    "        for w in words:\n",
    "            if w[1] in [\"Noun\"]:      # \"Adjective\", \"Verb\" 등을 포함할 수도 있습니다.\n",
    "                res.append(w[0])    # 명사일 때만 tokenized 에 저장하게 됩니다. \n",
    "        tokenized_10.append(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "spare-divorce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1694\n"
     ]
    }
   ],
   "source": [
    "print(len(tokenized_10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "surgical-elements",
   "metadata": {},
   "outputs": [],
   "source": [
    "okt = Okt()\n",
    "tokenized_11 = []\n",
    "with open(os.getenv('HOME')+'/aiffel/weat/synopsis_historical.txt', 'r') as file:\n",
    "    while True:\n",
    "        line = file.readline()\n",
    "        if not line: break\n",
    "        words = okt.pos(line, stem=True, norm=True)\n",
    "        res = []\n",
    "        for w in words:\n",
    "            if w[1] in [\"Noun\"]:      # \"Adjective\", \"Verb\" 등을 포함할 수도 있습니다.\n",
    "                res.append(w[0])    # 명사일 때만 tokenized 에 저장하게 됩니다. \n",
    "        tokenized_11.append(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "human-navigator",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "239\n"
     ]
    }
   ],
   "source": [
    "print(len(tokenized_11))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "literary-repair",
   "metadata": {},
   "outputs": [],
   "source": [
    "okt = Okt()\n",
    "tokenized_12 = []\n",
    "with open(os.getenv('HOME')+'/aiffel/weat/synopsis_western.txt', 'r') as file:\n",
    "    while True:\n",
    "        line = file.readline()\n",
    "        if not line: break\n",
    "        words = okt.pos(line, stem=True, norm=True)\n",
    "        res = []\n",
    "        for w in words:\n",
    "            if w[1] in [\"Noun\"]:      # \"Adjective\", \"Verb\" 등을 포함할 수도 있습니다.\n",
    "                res.append(w[0])    # 명사일 때만 tokenized 에 저장하게 됩니다. \n",
    "        tokenized_12.append(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ideal-speaking",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48\n"
     ]
    }
   ],
   "source": [
    "print(len(tokenized_12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "wired-teddy",
   "metadata": {},
   "outputs": [],
   "source": [
    "okt = Okt()\n",
    "tokenized_13 = []\n",
    "with open(os.getenv('HOME')+'/aiffel/weat/synopsis_adult.txt', 'r') as file:\n",
    "    while True:\n",
    "        line = file.readline()\n",
    "        if not line: break\n",
    "        words = okt.pos(line, stem=True, norm=True)\n",
    "        res = []\n",
    "        for w in words:\n",
    "            if w[1] in [\"Noun\"]:      # \"Adjective\", \"Verb\" 등을 포함할 수도 있습니다.\n",
    "                res.append(w[0])    # 명사일 때만 tokenized 에 저장하게 됩니다. \n",
    "        tokenized_13.append(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "unusual-housing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1647\n"
     ]
    }
   ],
   "source": [
    "print(len(tokenized_13))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "stuck-dance",
   "metadata": {},
   "outputs": [],
   "source": [
    "okt = Okt()\n",
    "tokenized_14 = []\n",
    "with open(os.getenv('HOME')+'/aiffel/weat/synopsis_thriller.txt', 'r') as file:\n",
    "    while True:\n",
    "        line = file.readline()\n",
    "        if not line: break\n",
    "        words = okt.pos(line, stem=True, norm=True)\n",
    "        res = []\n",
    "        for w in words:\n",
    "            if w[1] in [\"Noun\"]:      # \"Adjective\", \"Verb\" 등을 포함할 수도 있습니다.\n",
    "                res.append(w[0])    # 명사일 때만 tokenized 에 저장하게 됩니다. \n",
    "        tokenized_14.append(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "linear-rocket",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2265\n"
     ]
    }
   ],
   "source": [
    "print(len(tokenized_14))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "guided-january",
   "metadata": {},
   "outputs": [],
   "source": [
    "okt = Okt()\n",
    "tokenized_15 = []\n",
    "with open(os.getenv('HOME')+'/aiffel/weat/synopsis_animation.txt', 'r') as file:\n",
    "    while True:\n",
    "        line = file.readline()\n",
    "        if not line: break\n",
    "        words = okt.pos(line, stem=True, norm=True)\n",
    "        res = []\n",
    "        for w in words:\n",
    "            if w[1] in [\"Noun\"]:      # \"Adjective\", \"Verb\" 등을 포함할 수도 있습니다.\n",
    "                res.append(w[0])    # 명사일 때만 tokenized 에 저장하게 됩니다. \n",
    "        tokenized_15.append(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "celtic-click",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8779\n"
     ]
    }
   ],
   "source": [
    "print(len(tokenized_15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "alternative-easter",
   "metadata": {},
   "outputs": [],
   "source": [
    "okt = Okt()\n",
    "tokenized_16 = []\n",
    "with open(os.getenv('HOME')+'/aiffel/weat/synopsis_action.txt', 'r') as file:\n",
    "    while True:\n",
    "        line = file.readline()\n",
    "        if not line: break\n",
    "        words = okt.pos(line, stem=True, norm=True)\n",
    "        res = []\n",
    "        for w in words:\n",
    "            if w[1] in [\"Noun\"]:      # \"Adjective\", \"Verb\" 등을 포함할 수도 있습니다.\n",
    "                res.append(w[0])    # 명사일 때만 tokenized 에 저장하게 됩니다. \n",
    "        tokenized_16.append(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "conventional-condition",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5860\n"
     ]
    }
   ],
   "source": [
    "print(len(tokenized_16))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "general-scenario",
   "metadata": {},
   "outputs": [],
   "source": [
    "okt = Okt()\n",
    "tokenized_17 = []\n",
    "with open(os.getenv('HOME')+'/aiffel/weat/synopsis_adventure.txt', 'r') as file:\n",
    "    while True:\n",
    "        line = file.readline()\n",
    "        if not line: break\n",
    "        words = okt.pos(line, stem=True, norm=True)\n",
    "        res = []\n",
    "        for w in words:\n",
    "            if w[1] in [\"Noun\"]:      # \"Adjective\", \"Verb\" 등을 포함할 수도 있습니다.\n",
    "                res.append(w[0])    # 명사일 때만 tokenized 에 저장하게 됩니다. \n",
    "        tokenized_17.append(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "recreational-quantity",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "535\n"
     ]
    }
   ],
   "source": [
    "print(len(tokenized_17))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "accepting-manchester",
   "metadata": {},
   "outputs": [],
   "source": [
    "okt = Okt()\n",
    "tokenized_18 = []\n",
    "with open(os.getenv('HOME')+'/aiffel/weat/synopsis_war.txt', 'r') as file:\n",
    "    while True:\n",
    "        line = file.readline()\n",
    "        if not line: break\n",
    "        words = okt.pos(line, stem=True, norm=True)\n",
    "        res = []\n",
    "        for w in words:\n",
    "            if w[1] in [\"Noun\"]:      # \"Adjective\", \"Verb\" 등을 포함할 수도 있습니다.\n",
    "                res.append(w[0])    # 명사일 때만 tokenized 에 저장하게 됩니다. \n",
    "        tokenized_18.append(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "neutral-accident",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "387\n"
     ]
    }
   ],
   "source": [
    "print(len(tokenized_18))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "partial-arcade",
   "metadata": {},
   "outputs": [],
   "source": [
    "okt = Okt()\n",
    "tokenized_19 = []\n",
    "with open(os.getenv('HOME')+'/aiffel/weat/synopsis_comedy.txt', 'r') as file:\n",
    "    while True:\n",
    "        line = file.readline()\n",
    "        if not line: break\n",
    "        words = okt.pos(line, stem=True, norm=True)\n",
    "        res = []\n",
    "        for w in words:\n",
    "            if w[1] in [\"Noun\"]:      # \"Adjective\", \"Verb\" 등을 포함할 수도 있습니다.\n",
    "                res.append(w[0])    # 명사일 때만 tokenized 에 저장하게 됩니다. \n",
    "        tokenized_19.append(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "measured-provider",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4635\n"
     ]
    }
   ],
   "source": [
    "print(len(tokenized_19))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "incident-acrylic",
   "metadata": {},
   "outputs": [],
   "source": [
    "okt = Okt()\n",
    "tokenized_20 = []\n",
    "with open(os.getenv('HOME')+'/aiffel/weat/synopsis_fantasy.txt', 'r') as file:\n",
    "    while True:\n",
    "        line = file.readline()\n",
    "        if not line: break\n",
    "        words = okt.pos(line, stem=True, norm=True)\n",
    "        res = []\n",
    "        for w in words:\n",
    "            if w[1] in [\"Noun\"]:      # \"Adjective\", \"Verb\" 등을 포함할 수도 있습니다.\n",
    "                res.append(w[0])    # 명사일 때만 tokenized 에 저장하게 됩니다. \n",
    "        tokenized_20.append(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "another-ivory",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "801\n"
     ]
    }
   ],
   "source": [
    "print(len(tokenized_20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "romance-folks",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68856\n"
     ]
    }
   ],
   "source": [
    "print(len(tokenized_0)+len(tokenized_1)+len(tokenized_2)+len(tokenized_3)+len(tokenized_4)+len(tokenized_5)+len(tokenized_6)+len(tokenized_7)+len(tokenized_8)+len(tokenized_9)+len(tokenized_10)+len(tokenized_11)+len(tokenized_12)+len(tokenized_13)+len(tokenized_14)+len(tokenized_15)+len(tokenized_16)+len(tokenized_17)+len(tokenized_18)+len(tokenized_19)+len(tokenized_20))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aiffel",
   "language": "python",
   "name": "aiffel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
