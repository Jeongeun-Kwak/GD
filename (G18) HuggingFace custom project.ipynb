{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "opened-symphony",
   "metadata": {},
   "source": [
    "# (G18) HuggingFace 커스텀 프로젝트 만들기\n",
    "\n",
    "****\n",
    "# 커스텀 프로젝트 제작 (1) Processor\n",
    "\n",
    "## mrpc 데이터셋 분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "statutory-canberra",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from argparse import ArgumentParser\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "from transformers import BertTokenizer, TFBertForSequenceClassification, AutoConfig\n",
    "from dataclasses import asdict\n",
    "from transformers.data.processors.utils import DataProcessor, InputExample, InputFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "heated-conversion",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl:Load dataset info from /home/aiffel-dj20/tensorflow_datasets/glue/mrpc/1.0.0\n",
      "INFO:absl:Reusing dataset glue (/home/aiffel-dj20/tensorflow_datasets/glue/mrpc/1.0.0)\n",
      "INFO:absl:Constructing tf.data.Dataset glue for split None, from /home/aiffel-dj20/tensorflow_datasets/glue/mrpc/1.0.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3668"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 텐서플로우 제공 데이터\n",
    "data, info = tfds.load('glue/mrpc', with_info=True)\n",
    "info.splits['train'].num_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "sufficient-implementation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<TakeDataset shapes: {idx: (), label: (), sentence1: (), sentence2: ()}, types: {idx: tf.int32, label: tf.int64, sentence1: tf.string, sentence2: tf.string}>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['train'].take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "limiting-cambodia",
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = data['train'].take(1)\n",
    "for example in examples:\n",
    "    sentence1 = example['sentence1']\n",
    "    sentence2 = example['sentence2']\n",
    "    label = example['label']\n",
    "    print(sentence1)\n",
    "    print(sentence2)\n",
    "    print(label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "connected-exposure",
   "metadata": {},
   "source": [
    "## Processor의 활용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "quantitative-scoop",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataProcessor:\n",
    "    \"\"\"Base class for data converters for sequence classification data sets.\"\"\"\n",
    "\n",
    "    def get_example_from_tensor_dict(self, tensor_dict):\n",
    "        \"\"\"\n",
    "        Gets an example from a dict with tensorflow tensors.\n",
    "\n",
    "        Args:\n",
    "            tensor_dict: Keys and values should match the corresponding Glue\n",
    "                tensorflow_dataset examples.\n",
    "        \"\"\"\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def get_train_examples(self, data_dir):\n",
    "        \"\"\"Gets a collection of :class:`InputExample` for the train set.\"\"\"\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def get_dev_examples(self, data_dir):\n",
    "        \"\"\"Gets a collection of :class:`InputExample` for the dev set.\"\"\"\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def get_test_examples(self, data_dir):\n",
    "        \"\"\"Gets a collection of :class:`InputExample` for the test set.\"\"\"\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def get_labels(self):\n",
    "        \"\"\"Gets the list of labels for this data set.\"\"\"\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def tfds_map(self, example):\n",
    "        \"\"\"\n",
    "        Some tensorflow_datasets datasets are not formatted the same way the GLUE datasets are. This method converts\n",
    "        examples to the correct format.\n",
    "        \"\"\"\n",
    "        if len(self.get_labels()) > 1:\n",
    "            example.label = self.get_labels()[int(example.label)]\n",
    "        return example\n",
    "\n",
    "    @classmethod\n",
    "    def _read_tsv(cls, input_file, quotechar=None):\n",
    "        \"\"\"Reads a tab separated value file.\"\"\"\n",
    "        with open(input_file, \"r\", encoding=\"utf-8-sig\") as f:\n",
    "            return list(csv.reader(f, delimiter=\"\\t\", quotechar=quotechar))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "magnetic-rates",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MrpcProcessor(DataProcessor):\n",
    "    \"\"\"Processor for the MRPC data set (GLUE version).\"\"\"\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "    def get_example_from_tensor_dict(self, tensor_dict):\n",
    "        \"\"\"See base class.\"\"\"\n",
    "        return InputExample(\n",
    "            tensor_dict[\"idx\"].numpy(),\n",
    "            tensor_dict[\"sentence1\"].numpy().decode(\"utf-8\"),\n",
    "            tensor_dict[\"sentence2\"].numpy().decode(\"utf-8\"),\n",
    "            str(tensor_dict[\"label\"].numpy()),\n",
    "        )\n",
    "\n",
    "    def get_train_examples(self, data_dir):\n",
    "        \"\"\"See base class.\"\"\"\n",
    "        print(\"LOOKING AT {}\".format(os.path.join(data_dir, \"train.tsv\")))\n",
    "        return self._create_examples(self._read_tsv(os.path.join(data_dir, \"train.tsv\")), \"train\")\n",
    "\n",
    "    def get_dev_examples(self, data_dir):\n",
    "        \"\"\"See base class.\"\"\"\n",
    "        return self._create_examples(self._read_tsv(os.path.join(data_dir, \"dev.tsv\")), \"dev\")\n",
    "\n",
    "    def get_test_examples(self, data_dir):\n",
    "        \"\"\"See base class.\"\"\"\n",
    "        return self._create_examples(self._read_tsv(os.path.join(data_dir, \"test.tsv\")), \"test\")\n",
    "\n",
    "    def get_labels(self):\n",
    "        \"\"\"See base class.\"\"\"\n",
    "        return [\"0\", \"1\"]\n",
    "\n",
    "    def _create_examples(self, lines, set_type):\n",
    "        \"\"\"Creates examples for the training, dev and test sets.\"\"\"\n",
    "        examples = []\n",
    "        for (i, line) in enumerate(lines):\n",
    "            if i == 0:\n",
    "                continue\n",
    "            guid = \"%s-%s\" % (set_type, i)\n",
    "            text_a = line[3]\n",
    "            text_b = line[4]\n",
    "            label = None if set_type == \"test\" else line[0]\n",
    "            examples.append(InputExample(guid=guid, text_a=text_a, text_b=text_b, label=label))\n",
    "        return examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "painted-medicine",
   "metadata": {},
   "outputs": [],
   "source": [
    "processor = MrpcProcessor()\n",
    "examples = data['train'].take(1)\n",
    "\n",
    "for example in examples:\n",
    "    print('------원본데이터------')\n",
    "    print(example)  \n",
    "    example = processor.get_example_from_tensor_dict(example)\n",
    "    print('------processor 가공데이터------')\n",
    "    print(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caroline-jewelry",
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = (data['train'].take(1))\n",
    "for example in examples:\n",
    "    example = processor.get_example_from_tensor_dict(example)\n",
    "    example = processor.tfds_map(example)\n",
    "    print(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accredited-access",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_list = processor.get_labels()\n",
    "label_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rising-clinic",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_map = {label: i for i, label in enumerate(label_list)}\n",
    "label_map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "separated-cycling",
   "metadata": {},
   "source": [
    "****\n",
    "# 커스텀 프로젝트 제작 (2) Tokenizer와 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ranking-riverside",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = TFBertForSequenceClassification.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "computational-rebel",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _glue_convert_examples_to_features(examples, tokenizer, max_length, processor, label_list=None, output_mode=\"claasification\") :\n",
    "    if max_length is None :\n",
    "        max_length = tokenizer.max_len\n",
    "    if label_list is None:\n",
    "        label_list = processor.get_labels()\n",
    "        print(\"Using label list %s\" % (label_list))\n",
    "\n",
    "    label_map = {label: i for i, label in enumerate(label_list)}\n",
    "    labels = [label_map[example.label] for example in examples]\n",
    "\n",
    "    batch_encoding = tokenizer(\n",
    "        [(example.text_a, example.text_b) for example in examples],\n",
    "        max_length=max_length,\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "    )\n",
    "\n",
    "    features = []\n",
    "    for i in range(len(examples)):\n",
    "        inputs = {k: batch_encoding[k][i] for k in batch_encoding}\n",
    "\n",
    "        feature = InputFeatures(**inputs, label=labels[i])\n",
    "        features.append(feature)\n",
    "\n",
    "    for i, example in enumerate(examples[:5]):\n",
    "        print(\"*** Example ***\")\n",
    "        print(\"guid: %s\" % (example.guid))\n",
    "        print(\"features: %s\" % features[i])\n",
    "\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "functional-induction",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "developmental-direction",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "brazilian-latest",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "formal-lightweight",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unauthorized-thumbnail",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "demonstrated-psychology",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ahead-invitation",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "governing-garden",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "difficult-blind",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vietnamese-saint",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "regulation-afghanistan",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "chronic-moral",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fatal-maintenance",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "harmful-repair",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ethical-centre",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fixed-broad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "instant-hepatitis",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "standing-taylor",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "heavy-extreme",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "removed-comparison",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "plain-tribe",
   "metadata": {},
   "source": [
    "# 루브릭 평가\n",
    "\n",
    "\n",
    "|평가문항|상세기준|\n",
    "|:------|:------|\n",
    "|1. MNLI 데이터셋을 처리하는 전용 Processor 클래스를 정상적으로 구현하였다.|Processor 클래스에 대해 1개 이상의 example에 대한 단위테스트가 정상 진행되었다.|\n",
    "|2. BERT tokenizer와 Processor를 결합하여 데이터셋을 정상적으로 생성하였다.|MNLI 데이터셋의 입력과 라벨의 정의에 잘 맞는 tf.data.Dataset 인스턴스가 얻어졌다.|\n",
    "|3. MNLI 데이터셋에 대해 BERT 모델을 fine-tuning한 결과 기대한 수준의 모델 성능을 확인하였다.|테스트셋에 대해 80% 이상의 accuracy를 확인하였다.|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "multiple-state",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "exposed-storm",
   "metadata": {},
   "source": [
    "# 회고"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "forty-instruction",
   "metadata": {},
   "source": [
    "죄송합니다! 오늘이 기한인 걸 까먹고 있었어요!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aiffel",
   "language": "python",
   "name": "aiffel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
