{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "silent-syntax",
   "metadata": {},
   "source": [
    "# (G10) Transformer로 번역기 만들기\n",
    "\n",
    "- 나름대로 혁신적이었던 Seq2seq 구조로 번역기를 만들었으나 성능이 기대에 미치지 않아 실망한 사람들도 있을 것이다. 하지만 Transformer는 다르다.\n",
    "\n",
    "\n",
    "- Trasformer는 현재까지도 각종 번역 부문에서 최고의 성능을 자랑하는 모델이니 이번에는 정말 멋진 번역기를 만들 수 있을 것이다. 이전 강의 노드에서 배웠던 개념들이 어떻게 구현되는지 보자.\n",
    "\n",
    "\n",
    "- Trasformer 모델은 앞으로 자연어처리 분야에서는 항상 빠지지 않는 중요한 모델 구조의 근간이 되기 때문에 오늘 구현 실습을 통해 트랜스포머의 구조를 꼼꼼히 파악하자.\n",
    "\n",
    "\n",
    "## 준비물\n",
    "\n",
    "- 터미널을 열고 프로젝트를 위한 디렉토리를 생성하자.\n",
    "```c\n",
    "$ mkdir -p ~/aiffel/transformer\n",
    "```\n",
    "\n",
    "\n",
    "- 실습에서는 한국어가 포함된 말뭉치를 사용하므로, 한국어를 잘 시각화하기 위한 준비가 필요하다. 다만 ```matplotlib``` 라이브러리의 기본 폰트는 한국어를 지원하지 않기에 Attention Map을 확인하기 위해 한국어를 지원하는 폰트로 변경해 주도록 한다. 아직 컴퓨터에 글꼴이 설치되어 있지 않다면, 터미널에서 나눔 글꼴을 설치한다.\n",
    "```c\n",
    "$ sudo apt -qq -y install fonts-nanum\n",
    "```\n",
    "\n",
    "\n",
    "- 아래 코드는 앞으로 필요한 경우 한글을 실행해야 할 때 미리 한 번씩 실행해주면 된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "headed-placement",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    " \n",
    "%config InlineBackend.figure_format = 'retina'\n",
    " \n",
    "import matplotlib.font_manager as fm\n",
    "fontpath = '/usr/share/fonts/truetype/nanum/NanumBarunGothic.ttf'\n",
    "font = fm.FontProperties(fname=fontpath, size=9)\n",
    "plt.rc('font', family='NanumBarunGothic') \n",
    "mpl.font_manager._rebuild()\n",
    "\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dangerous-repeat",
   "metadata": {},
   "source": [
    "****\n",
    "# 내부 모듈 구현하기 \n",
    "\n",
    "- 이번 코스는 Transformer를 완성하는 데에 필요한 모듈들을 하나하나 만든 후, 조립하며 완성하는 방식으로 진행할 것이다.\n",
    "\n",
    "\n",
    "- tensor로 변환한 입력 데이터가 주어졌다고 가정하고 흐름을 생각해보자.\n",
    "- 최조의 텍스트 입력 데이터는 ```[batch_size x length]```의 형태를 가지고 있을 것이다.\n",
    "- 번역이 끝나고 난 최종 출력 데이터는 ```[batch_size x length x vocab_size]```의 형태를 가지게 된닫.\n",
    "- 번역 문제는 매 스텝마다 ```vocab_size```만큼의 클래스 개수 중에 적당한 단어를 선택하는 작업을 ```length```만큼 반복하는 것이다.\n",
    "- 모델 구성하는 과정에서 레이러를 통과할 때 마다 텐서의 shape가 어떻게 바뀌는지 살펴보자.\n",
    "\n",
    "> 1. 입력 데이터 --> ```[batch_size x length]```    \n",
    "> 2. Sourde & Target Embedding --> ```[batch_size x length x d_emb]```    \n",
    "> 3. **Positional Encoding** --> 2번의 결과에 더해지므로 shape 변화 없음.    \n",
    "> 4. **Multi-Head Attention**는 아래와 같이 여러 개의 서브 모듈들이 존재한다.\n",
    " >> (1) **Split Heads** --> ```[batch_size x length x heads x (d_emb / n_heads)]```    \n",
    " >> (2) **Masking for Masked Attention**    \n",
    " >> (3) **Scaled Dot Prodect Attention**    \n",
    " >> (4) **Combine Heads** --> ```[batch_size x length x d_emb]```    \n",
    "> 5. Resudual Connection     \n",
    "> 6. Layer Normalization     \n",
    "> 7. **Position-wise Feed-Forward Network** --> ```[batch_size x length x d_ff]```\n",
    "> 8.  Output Linear Layer --> ```[batch_size x length x vocab_size]```\n",
    "\n",
    "\n",
    "- 굵게 표시된 모듈을 제외하면 나머지는 텐서플로우 내부에 이미 구현체가 포함되어 있어서 간단하게 사용할 수 있다. \n",
    "\n",
    "\n",
    "##  Posotional Encoding\n",
    "\n",
    "![](https://user-images.githubusercontent.com/67767735/116876063-d4114a80-ac56-11eb-8797-1ae93c9384f5.png)\n",
    "- 우선 Positional Encoding부터 살펴보자.\n",
    "- 먼저 프로젝트에 사용할 라이브러리를 ```import```해오자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "incredible-ebony",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4.1\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import re\n",
    "import os\n",
    "import io\n",
    "import time\n",
    "import random\n",
    "\n",
    "import seaborn # Attention 시각화를 위해 필요!\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "offensive-arcade",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "# Posotional Encoding\n",
    "def positional_encoding(pos, d_model):\n",
    "    def cal_angle(position, i):\n",
    "        return position / np.power(10000, int(i) / d_model)\n",
    "\n",
    "    def get_posi_angle_vec(position):\n",
    "        return [cal_angle(position, i) for i in range(d_model)]\n",
    "\n",
    "    sinusoid_table = np.array([get_posi_angle_vec(pos_i) for pos_i in range(pos)])\n",
    "\n",
    "    sinusoid_table[:, 0::2] = np.sin(sinusoid_table[:, 0::2])\n",
    "    sinusoid_table[:, 1::2] = np.cos(sinusoid_table[:, 1::2])\n",
    "\n",
    "    return sinusoid_table\n",
    "\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "korean-steps",
   "metadata": {},
   "source": [
    "- 위 소스는 가급적이면 그대로 사용하는 것이 좋다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tired-brunswick",
   "metadata": {},
   "source": [
    "## Multi-Head Attention\n",
    "\n",
    "![](https://user-images.githubusercontent.com/67767735/116876171-fe630800-ac56-11eb-839c-7311ab3ec00b.png)\n",
    "- Multi-Head Attention은 여러 개의 서브 모듈을 결합하여 완성한다.\n",
    "- Embedding된 입력을 **Head 수로 분할**하는 ```split-heads()```, 분할된 입력으로부터 **Attention 값을 구하는** ```scaled_dot_product_attention()```, 연산이 종료되고 **분할된 Head를 다시 하나로 결합**시켜주는 ```combine_heads()```까지 ```MultiHeadAttention``` 클래스를 정의하여 모두 포함시켜주자.\n",
    "\n",
    "\n",
    "- 뭔가 빠진 것이 있다면 바로 Masking 부분인데, **마스크의 형태를 결정하는 것은 모델 외부의 훈련 데이터**이기 때문에 Masking을 생성하는 함수는 ```MultiHeadAttention``` 외부에 정의되는 것이 올바르다.    \n",
    "- 마스크를 생성하는 함수는 모델을 완성한 후에 구현하도록 하겠으나, 생성된 마스크를 처리할 수 있도록 ```scaled_dot_product_attention()```에는 아래 한 줄을 포함하자.\n",
    "```c\n",
    "# scaled_qk: Attention을 위한 Softmax 직전의 Scaled QK\n",
    "if mask is not None: scaled_qk += (mask * -1e9)\n",
    "```\n",
    "\n",
    "\n",
    "- 아래 소스의 빈칸을 채워 ```MultiHeadAttention``` 클래스를 완성해보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "false-cleanup",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "class MultiHeadAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, num_heads):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        self.num_heads = num_heads\n",
    "        self.d_model = d_model\n",
    "        \n",
    "        self.depth = d_model // self.num_heads\n",
    "        \n",
    "        self.W_q = tf.keras.layers.Dense(d_model) # Linear Layer\n",
    "        self.W_k = tf.keras.layers.Dense(d_model)\n",
    "        self.W_v = tf.keras.layers.Dense(d_model)\n",
    "        \n",
    "        self.linear = tf.keras.layers.Dense(d_model)\n",
    "\n",
    "    def scaled_dot_product_attention(self, Q, K, V, mask):\n",
    "        d_k = tf.cast(K.shape[-1], tf.float32)\n",
    "        \n",
    "        # 내 코드: scaled_qk = tf.tensordot(Q, tf.transpose(K), axes=1) / tf.sqrt(d_k)\n",
    "        QK = tf.matmul(Q, K, transpose_b=True)\n",
    "        scaled_qk = QK / tf.math.sqrt(d_k)\n",
    "        \n",
    "        if mask is not None: scaled_qk += (mask * -1e9) \n",
    "\n",
    "        # 1. Attention Weights 값 구하기 -> attentions\n",
    "        attentions = tf.nn.softmax(scaled_qk, axis=-1)\n",
    "        \n",
    "        # 2. Attention 값을 V에 곱하기 -> out \n",
    "        # 내 코드: out = tf.tensordot(attention, V, axes=1)\n",
    "        out = tf.matmul(attentions, V)\n",
    "        \n",
    "        return out, attentions\n",
    "        \n",
    "\n",
    "    def split_heads(self, x):\n",
    "        \"\"\"\n",
    "         Embedding을 Head의 수로 분할하는 함수\n",
    "         x: [ batch x length x emb ]\n",
    "         return: [ batch x length x heads x self.depth ]\n",
    "        \n",
    "        \"\"\"\n",
    "        bsz = x.shape[0] # x의 1차원 값 \n",
    "        split_x = tf.reshape(x, (bsz, -1, self.num_heads, self.depth))\n",
    "        split_x = tf.transpose(split_x, perm = [0, 2, 1, 3])\n",
    "        \n",
    "        return split_x\n",
    "\n",
    "    def combine_heads(self, x):\n",
    "        \"\"\"\n",
    "        분할된 Embedding을 하나로 결합하는 함수\n",
    "        x: [ batch x length x heads x self.depth ]\n",
    "        return: [ batch x length x emb ]\n",
    "        \n",
    "        \"\"\"\n",
    "        bsz = x.shape[0]\n",
    "        combined_x = tf.transpose(x, perm = [0, 2, 1, 3])\n",
    "        combine_x = tf.reshape(combine_x, (bsz, -1, self.d_model))\n",
    "        \n",
    "        return combined_x\n",
    "    \n",
    "\n",
    "    def call(self, Q, K, V, mask):\n",
    "     \n",
    "        \"\"\"\n",
    "        아래 순서에 따라 소스를 작성하세요.\n",
    "        Step 1: Linear_in(Q, K, V) -> WQ, WK, WV\n",
    "        Step 2: Split Heads(WQ, WK, WV) -> WQ_split, WK_split, WV_split\n",
    "        Step 3: Scaled Dot Product Attention(WQ_split, WK_split, WV_split)\n",
    "                 -> out, attention_weights\n",
    "        Step 4: Combine Heads(out) -> out\n",
    "        Step 5: Linear_out(out) -> out\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        WQ = self.W_q(Q)\n",
    "        WK = self.W_k(K)\n",
    "        WV = self.W_v(V)\n",
    "        \n",
    "        WQ_splits = self.split_heads(WQ)\n",
    "        WK_splits = self.split_heads(WK)\n",
    "        WV_splits = self.split_heads(WV)\n",
    "        \n",
    "        out, attention_weights = self.scaled_dot_product_attention(\n",
    "                                                                   WQ_splits, \n",
    "                                                                   WK_splits, \n",
    "                                                                   WV_splits, \n",
    "                                                                   mask\n",
    "                                                                   )\n",
    "        \n",
    "        out = self.combine_heads(out)\n",
    "        out = self.linear(out)\n",
    "        \n",
    "        return out, attention_weights\n",
    "\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "brutal-aggregate",
   "metadata": {},
   "source": [
    "- 쉽진 않은 작업니다. 필자는는 Multi-Head Attention을 처음 구현할 적에 Head를 나눈다는 개념이 너무 헷갈려서 반복문을 돌며 ```[idx : idx + self.depth]```로 인덱싱해서 처리를 했던 기억이 있다.\n",
    "- 이렇게 하면 연산하는 데 정말 많은 시간이 걸리니 부디 독자들은 이런 시행착오를 겪지 않았으면 좋겠다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "immediate-element",
   "metadata": {},
   "source": [
    "## Position-wise Feed-Forward Network\n",
    "\n",
    "![](https://user-images.githubusercontent.com/67767735/116876328-4124e000-ac57-11eb-8599-5530ee517a19.png)\n",
    "- 논문에서도 설명이 간략했으며 구현도 아주 쉬운 편이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "minor-salvation",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PoswiseFeedForwardNet(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, d_ff):\n",
    "        super(PoswiseFeedForwardNet, self).__init__()\n",
    "        self.w_1 = tf.keras.layers.Dense(d_ff, activation='relu')\n",
    "        self.w_2 = tf.keras.layers.Dense(d_model)\n",
    "\n",
    "    def call(self, x):\n",
    "        out = self.w_1(x)\n",
    "        out = self.w_2(out)\n",
    "            \n",
    "        return out\n",
    "\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "variable-territory",
   "metadata": {},
   "source": [
    "- ```d_ff```는 논문의 설명대로라면 ```2048```일 것이고, ```d_model```은 ```512```일 것이다. ```[batch x length x d_model]```의 입력을 받아 ```w_1```이 **2048차원으로 매핑**하고 활성함수 **ReLU**를 적용한 후, 다시 ```w_2```를 통해 **512차원으로 되돌리는 과정**까지의 **FFN**을 살펴보았다.  \n",
    "\n",
    "****\n",
    "# 모듈 조립하기 \n",
    "\n",
    "- 여기까지 내부에 포함될 모듈등을 모두 완성해보았다. 이 모든 모듈들을 가지고 트랜스포머를 완성할 수 있는데, 정확하게는 **트랜스포머의 Encoder 한 층**과 **Decoder 한 층을 각각 완성**할 수 있는 것이다.\n",
    "\n",
    "\n",
    "- 논문에는 Encoder와 Decoder가 각각 6번씩 쓰였으니 위 코드를 5번 더 짜야 논문 속 트랜스포머를 구현할 수 있는 것이 아니냐고 물을 수 있다. 하지만 우린 더 효율적인 방법으로 트랜스포머를 완성할 것이니 걱정은 내려놓는 것이 좋다.\n",
    "\n",
    "\n",
    "- [Attention is All you Need](https://papers.nips.cc/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf)의 9 페이지를 보면 표가 하나 있는데, 이는 **트랜스포머가 얼마나 많은 실험을 통해서 탄생한 모델**인지를 보여준다.\n",
    "- 이런 실험을 가능하게 하려면 **모델이 동적으로 완성될 수 있게끔** 해야 한다. 즉, 레이어 수를 원하는 만큼 쌍아 실험을 자유자재로 할 수 있게 모델을 완성하자는 것이다.\n",
    "\n",
    "\n",
    "- 방법은 단순하다. 마치 텐서플로우읜 ```Dense``` 레이어를 사용하듯이 ```EncoderLayer```, ```DecoderLayer```를 쓸 수 있게 ```tf.keras.layers.Layer``` **클래스를 상속받아 레이어 클래스로 정의**해주면 된다. 우리는 이미 ```Layer``` 클래스를 정의해본 적이 있는데, 바로 직전의 ```MultiHeadAttention```이 그렇렇게 정의된 레이어이다. 이 반법을 사용하면 아래와 같은 용법으로 트랜스포머 레이어를 사용할 수 있다.\n",
    "```c\n",
    "N = 10\n",
    "# 10개의 Linear Layer를 한 방에!\n",
    "linear_layers = [tf.keras.layers.Dense(30) for _ in range(N)]\n",
    "# 10개의 Encoder Layer도 한 방에!\n",
    "enc_layers = [TransformerEncoderLayer(30) for _ in range(N)]\n",
    "```\n",
    "\n",
    "\n",
    "- 혹시라도 이런 동적 방식이 낯설다면 지금부터라도 익숙해지는 것이 좋다.\n",
    "\n",
    "\n",
    "## Encoder 레이어 구현하기 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "substantial-trader",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "class EncoderLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, n_heads, d_ff, dropout):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "\n",
    "        self.enc_self_attn = MultiHeadAttention(d_model, n_heads)\n",
    "        self.ffn = PoswiseFeedForwardNet(d_model, d_ff)\n",
    "\n",
    "        self.norm_1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.norm_2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "\n",
    "        self.do = tf.keras.layers.Dropout(dropout)\n",
    "        \n",
    "    def call(self, x, mask):\n",
    "\n",
    "        \"\"\"\n",
    "        Multi-Head Attention\n",
    "        \"\"\"\n",
    "        residual = x\n",
    "        out = self.norm_1(x)\n",
    "        out, enc_attn = self.enc_self_attn(out, out, out, mask)\n",
    "        out = self.do(out)\n",
    "        out += residual\n",
    "        \n",
    "        \"\"\"\n",
    "        Position-Wise Feed Forward Network\n",
    "        \"\"\"\n",
    "        residual = out\n",
    "        out = self.norm_2(out)\n",
    "        out = self.ffn(out)\n",
    "        out = self.do(out)\n",
    "        out += residual\n",
    "        \n",
    "        return out, enc_attn\n",
    "\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "urban-capability",
   "metadata": {},
   "source": [
    "- 트랜스포머의 구현은 정말 많은데, 그중에서 **Normalization Layer의 위치**에 대한 논의가 종종 나온다. 실제 논문에서는 *[Input] - [Module] - [Residual] - [Norm](Module=MHA, FFN)*으로 표현되어 있지만 정작 Official 구현인 구글의 Tensor2Tensor에서는 *[Input] - [Norm] - [Module] - [Residual] 방식을 사용했다.\n",
    "\n",
    "\n",
    "- 강의 작성자는 자신의 경험에 따라 레이어가 많아질수록 후자가 약간 더 좋은 성능을 보였기에 논문 대신 Official 구현을 따르길 권장한다. 이번 프로젝트는 소규모라서 큰 차이가 나지 않으니 알아두기만 해도 괜찮을 것이다.\n",
    "\n",
    "\n",
    "- 참고로 트랜스포머의 Layer Normalization의 위치에 대한 논의를 다룬 [On Layer Normalization in the Transformer Architecture](https://arxiv.org/pdf/2002.04745.pdf)이라는 제목의 논문이 2020년 초반에 발표되었다. 이 논문에서는 모듈 앞에 Normalization Layer를 두는 pre-LN 방식이 왜 유리한지 설명하고 있다.\n",
    "\n",
    "\n",
    "## Decoder 레이어 구현하기\n",
    "\n",
    "- 위 ```EncoderLayer``` 클래스를 참고하여 ```DecoderLayer``` 클래스를 완성하자.\n",
    "- 참고로 Decoder에서는 두 번의 Attention이 진행되니 반환되는 Attention도 2개이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "certified-upgrade",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "class DecoderLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, n_heads, d_ff, dropout):\n",
    "        super(DecoderLayer, self).__init__()\n",
    "\n",
    "        self.dec_self_attn = MultiHeadAttention(d_model, n_heads)\n",
    "        self.enc_dec_attn = MultiHeadAttention(d_model, n_heads)\n",
    "        \n",
    "        self.ffn = PoswiseFeedForwardNet(d_model, d_ff)\n",
    "\n",
    "        self.norm_1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.norm_2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.norm_3 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        \n",
    "        self.do = tf.keras.layers.Dropout(dropout)\n",
    "        \n",
    "    def call(self, x, enc_out, causality_mask, padding_mask):\n",
    "\n",
    "        \"\"\"\n",
    "        Masked Multi-Head Attention\n",
    "        \"\"\"\n",
    "        residual = x\n",
    "        out = self.norm_1(x)\n",
    "        out, dec_attn = self.dec_self_attn(out, out, out, causality_mask)\n",
    "        out = self.do(out)\n",
    "        out += residual\n",
    "        \n",
    "        \"\"\"\n",
    "        Multi-Head Attention\n",
    "        \"\"\"\n",
    "        residual = x\n",
    "        out = self.norm_2(x)\n",
    "        out, dec_enc_attn = self.enc_dec_attn(out, enc_out, enc_out, padding_mask)\n",
    "        out = self.do(out)\n",
    "        out += residual\n",
    "        \n",
    "        \"\"\"\n",
    "        Position-Wise Feed Forward Network\n",
    "        \"\"\"\n",
    "        residual = out\n",
    "        out = self.norm_3(out)\n",
    "        out = self.ffn(out)\n",
    "        out = self.do(out)\n",
    "        out += residual\n",
    "        \n",
    "        return out, dec_attn, dec_enc_attn\n",
    "\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "straight-suffering",
   "metadata": {},
   "source": [
    "- ```EncoderLayer```와 ```DecoderLayer```를 모두 정의했으니 이를 조립하는 것은 어렵지 않을 것이다. 이를 이용해 ```Encoder```와 ```Decoder``` 클래스를 정의해보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "adequate-engine",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "class Encoder(tf.keras.Model):\n",
    "    def __init__(self,\n",
    "                 n_layers,\n",
    "                 d_model,\n",
    "                 n_heads,\n",
    "                 d_ff,\n",
    "                 dropout):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.n_layers = n_layers\n",
    "        self.enc_layers = [EncoderLayer(d_model, n_heads, d_ff, dropout) \n",
    "                        for _ in range(n_layers)]\n",
    "    \n",
    "        self.do = tf.keras.layers.Dropout(dropout)\n",
    "        \n",
    "    def call(self, x, mask):\n",
    "        out = x\n",
    "    \n",
    "        enc_attns = list()\n",
    "        for i in range(self.n_layers):\n",
    "            out, enc_attn = self.enc_layers[i](out, mask)\n",
    "            enc_attns.append(enc_attn)\n",
    "        \n",
    "        return out, enc_attns\n",
    "\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "increased-canberra",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "class Decoder(tf.keras.Model):\n",
    "    def __init__(self,\n",
    "                 n_layers,\n",
    "                 d_model,\n",
    "                 n_heads,\n",
    "                 d_ff,\n",
    "                 dropout):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.n_layers = n_layers\n",
    "        self.dec_layers = [DecoderLayer(d_model, n_heads, d_ff, dropout) \n",
    "                            for _ in range(n_layers)]\n",
    "                            \n",
    "                            \n",
    "    def call(self, x, enc_out, causality_mask, padding_mask):\n",
    "        out = x\n",
    "    \n",
    "        dec_attns = list()\n",
    "        dec_enc_attns = list()\n",
    "        for i in range(self.n_layers):\n",
    "            out, dec_attn, dec_enc_attn = \\\n",
    "            self.dec_layers[i](out, enc_out, causality_mask, padding_mask)\n",
    "\n",
    "            dec_attns.append(dec_attn)\n",
    "            dec_enc_attns.append(dec_enc_attn)\n",
    "\n",
    "        return out, dec_attns, dec_enc_attns\n",
    "\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "compact-fever",
   "metadata": {},
   "source": [
    "## Transformer 완성하기\n",
    "\n",
    "- 정의된 ```Encoder```와 ```Decoder```를 가지고 최종적으로 트랜스포머를 완성해보자.\n",
    "- 아래 조건을 만족하며 소스 빈칸을 채워 ```Transformer``` 클래스를 완성하자.\n",
    "\n",
    "> <조건>\n",
    "> 1. ```shared``` 변수를 매개변수로 받아 ```True```일 경우 **Decoder Embedding과 출력층 Linear의 Weight를 공유**할 수 있게 하라. Weight가 공유될 경우 Embedding 값에 **sqrt(d_model)**을 곱해줘야 하는 것도 잊으면 안된다. (참고: ```tf.keras.layers.Layer.set_weights()```)\n",
    "> 2. 우리가 정의한 ```positioanl_encoding```의 반환값 형태는 ```[length x d_model]```인데, 이를 더해 줄 Embedding 값 형태가 ```[batch x length x d_model]```이라서 연산이 불가능하다. **연산이 가능하도록 수정**하자. (참고: ```tf.expand_dims()```, ```np.newaxis```)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "parliamentary-insulation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "class Transformer(tf.keras.Model):\n",
    "    def __init__(self,\n",
    "                 n_layers,\n",
    "                 d_model,\n",
    "                 n_heads,\n",
    "                 d_ff,\n",
    "                 src_vocab_size,\n",
    "                 tgt_vocab_size,\n",
    "                 pos_len,\n",
    "                 dropout=0.2,\n",
    "                 shared=True):\n",
    "        super(Transformer, self).__init__()\n",
    "        self.d_model = tf.cast(d_model, tf.float32)\n",
    "\n",
    "        # 1. Embedding Layer 정의\n",
    "        self.enc_emb = tf.kers.layers.Embedding(src_vocab_size, d_model)\n",
    "        self.dec_emb = tf.kers.layers.Embedding(src_vocab_size, d_model)\n",
    "        \n",
    "        # 2. Positional Encoding 정의, Dropout 정의\n",
    "        self.pos_encoding = positional_encoding(pos_len, d_model)\n",
    "        self.do = tf.keras.layers.Dropout(dropout)\n",
    "        \n",
    "        # 3. Encoder / Decoder 정의\n",
    "        self.encoder = Encoder(n_layers, d_model, n_heads, d_ff, dropout)\n",
    "        self.decoder = Decoder(n_layers, d_model, n_heads, d_ff, dropout)\n",
    "        \n",
    "        # 4. Output Linear 정의\n",
    "        self.fc = tf.keras.layers.Dense(tgt_vocab_size)\n",
    "        \n",
    "        # 5. Shared Weights\n",
    "        self.shared = shared\n",
    "        \n",
    "        if shared: self.fc.set_weights(tf.transpose(self.dec_emb.weights)) \n",
    "       \n",
    "    def embedding(self, emb, x):\n",
    "        \"\"\"\n",
    "        입력된 정수 배열을 Embedding + Pos Encoding\n",
    "        + Shared일 경우 Scaling 작업 포함\n",
    "\n",
    "        x: [ batch x length ]\n",
    "        return: [ batch x length x emb ]\n",
    "        \"\"\"\n",
    "        seq_len = x.shape[1]\n",
    "        out = emb(x)\n",
    "        \n",
    "        if self.shared: out *= tf.math.sqrt(self.d_model)\n",
    "        \n",
    "        out += self.pos_encoding[np.newaxis, ...][:, :seq_len, :]\n",
    "        out = self.do(out)\n",
    "        \n",
    "        return out\n",
    "\n",
    "        \n",
    "    def call(self, enc_in, dec_in, enc_mask, causality_mask, dec_mask):\n",
    "        \"\"\"\n",
    "        아래 순서에 따라 소스를 작성하세요.\n",
    "\n",
    "        Step 1: Embedding(enc_in, dec_in) -> enc_in, dec_in\n",
    "        Step 2: Encoder(enc_in, enc_mask) -> enc_out, enc_attns\n",
    "        Step 3: Decoder(dec_in, enc_out, mask)\n",
    "                -> dec_out, dec_attns, dec_enc_attns\n",
    "        Step 4: Out Linear(dec_out) -> logits\n",
    "        \"\"\"\n",
    "        enc_in = self.embedding(self.enc_emb, enc_in)\n",
    "        dec_in = self.embeddong(self.dec_emb, dec_in)\n",
    "        \n",
    "        enc_out, enc_attns = self.encoder(enc_in, enc_mask)\n",
    "        \n",
    "        dec_out, dec_attns, dec_enc_attns = \\\n",
    "        self.decoder(dec_in, enc_out, causality_mask, dec_mask)\n",
    "        \n",
    "        logits = self.fc(dec_out)\n",
    "        \n",
    "        return logits, enc_attns, dec_attns, dec_enc_attns\n",
    "\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "indirect-video",
   "metadata": {},
   "source": [
    "****\n",
    "# 모델 밖의 조력자들\n",
    "\n",
    "- **Masking**을 살펴보자.\n",
    "- 그리고 트랜스포머의 **Learning Rate**가 일반적이지 않다는 것도 기억하고 있을 것이다.\n",
    "- 지금부터는 **모델 외적인 부분을 정의**해 주도록 하겠다.\n",
    "- 이번 스텝에서는 데이터의 특성이나 학습 과정에 따라 달라지는 부분을 다루게 된다.\n",
    "\n",
    "\n",
    "- 먼저 Masking은 이전 노드에서 배운 ```generate_causality_mask()```에 약간의 소스 코드만 추가해서 사용하면 된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "demographic-comedy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "def generate_padding_mask(seq):\n",
    "    seq = tf.cast(tf.math.equal(seq, 0), tf.float32)\n",
    "    return seq[:, tf.newaxis, tf.newaxis, :]\n",
    "\n",
    "def generate_causality_mask(src_len, tgt_len):\n",
    "    mask = 1 - np.cumsum(np.eye(src_len, tgt_len), 0)\n",
    "    return tf.cast(mask, tf.float32)\n",
    "\n",
    "def generate_masks(src, tgt):\n",
    "    enc_mask = generate_padding_mask(src)\n",
    "    dec_mask = generate_padding_mask(tgt)\n",
    "\n",
    "    dec_enc_causality_mask = generate_causality_mask(tgt.shape[1], src.shape[1])\n",
    "    dec_enc_mask = tf.maximum(enc_mask, dec_enc_causality_mask)\n",
    "\n",
    "    dec_causality_mask = generate_causality_mask(tgt.shape[1], tgt.shape[1])\n",
    "    dec_mask = tf.maximum(dec_mask, dec_causality_mask)\n",
    "\n",
    "    return enc_mask, dec_enc_mask, dec_mask\n",
    "\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "intermediate-friend",
   "metadata": {},
   "source": [
    "- ```generate_padding_mask()```는 Attention을 할 때에 ```<PAD>``` 토큰에도 Attention을 주는 것을 방지해주는 역할을 한다. \n",
    "- 일전에 Seq2Seq 모델에서 Loss에 대한 Masking을 해줄 때도 위와 같은 방법으로 진행했었다.\n",
    "- 한 배치 데이터에서 ```<PAD>``` 토큰으로 이뤄진 부분을 모두 찾아내는 마스크를 생성하자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "marked-uganda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x504 with 3 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 208,
       "width": 426
      },
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "batch, length = 16, 20\n",
    "src_padding = 5\n",
    "tgt_padding = 15\n",
    "\n",
    "src_pad = tf.zeros(shape=(batch, src_padding))\n",
    "tgt_pad = tf.zeros(shape=(batch, tgt_padding))\n",
    "\n",
    "sample_data = tf.ones(shape=(batch, length))\n",
    "\n",
    "sample_src = tf.concat([sample_data, src_pad], axis=-1)\n",
    "sample_tgt = tf.concat([sample_data, tgt_pad], axis=-1)\n",
    "\n",
    "enc_mask, dec_enc_mask, dec_mask = \\\n",
    "generate_masks(sample_src, sample_tgt)\n",
    "\n",
    "fig = plt.figure(figsize=(7, 7))\n",
    "\n",
    "ax1 = fig.add_subplot(131)\n",
    "ax2 = fig.add_subplot(132)\n",
    "ax3 = fig.add_subplot(133)\n",
    "\n",
    "ax1.set_title('1) Encoder Mask')\n",
    "ax2.set_title('2) Encoder-Decoder Mask')\n",
    "ax3.set_title('3) Decoder Mask')\n",
    "\n",
    "ax1.imshow(enc_mask[:3, 0, 0].numpy(), cmap='Dark2')\n",
    "ax2.imshow(dec_enc_mask[0, 0].numpy(), cmap='Dark2')\n",
    "ax3.imshow(dec_mask[0, 0].numpy(), cmap='Dark2')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "underlying-parliament",
   "metadata": {},
   "source": [
    "- 첫번째 마스크는 각 배치 별로 **데이터의 꼬리 부분을 Masking**하는 형태임을 알 수 있다. \n",
    "- 두번째와 세번째에 있는 Decoder가 연관된 마스크는 낯설어보일 수 있다. 이것이 바로 **Causality Mask와 padding Mask를 결합한 형태**이다.\n",
    "- 자기 회귀적인 특성을 살리기 위해 Masked Multi-Head Attention에서 **인과 관계 마스킹**을 했었다. 인과 관계를 가리는 것도 중요하지만 Decoder 역시 ```<PAD>``` 토큰은 피해 가야 하기 때문에 이런 형태에 마스크가 사용되는 것이다.\n",
    "\n",
    "\n",
    "- 또한 트랜스포머는 고정된 Learning Rate를 사용하지 않았다. 논문의 해당 부분을 Optimizer까지 포함하여 다시 한번 살펴보자.\n",
    "- 이전 노드에서 Learning Rate를 ```numpy```로 간단히 구현했었는데, 이번엔 **Tensorflow 상에서 잘 구동될 수 있도록** ```LearningRateSchedule``` 클래스를 상속받아 구현해보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bright-qatar",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "class LearningRateScheduler(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "    def __init__(self, d_model, warmup_steps=4000):\n",
    "        super(LearningRateScheduler, self).__init__()\n",
    "        self.d_model = d_model\n",
    "        self.warmup_steps = warmup_steps\n",
    "    \n",
    "    def __call__(self, step):\n",
    "        arg1 = step ** -0.5\n",
    "        arg2 = step * (self.warmup_steps ** -1.5)\n",
    "        \n",
    "        return (self.d_model ** -0.5) * tf.math.minimum(arg1, arg2)\n",
    "\n",
    "learning_rate = LearningRateScheduler(512)\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate,\n",
    "                                     beta_1=0.9,\n",
    "                                     beta_2=0.98, \n",
    "                                     epsilon=1e-9)\n",
    "\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "killing-protein",
   "metadata": {},
   "source": [
    "- 트랜스포머가 제안한 수식이 아니더라도 **가변적인 Learning Rate를 사용하려면** 위와 같이 구현하면 된다. Optimizer와 Scheduler를 연결하는 과정도 아주 간단하다.\n",
    "- Optimizer는 논문에 정의된 대로 Adam Optimizer를 사용하며 세부 파라미터도 동일하게 맞춰 준다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "automated-champagne",
   "metadata": {},
   "source": [
    "****"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "purple-camera",
   "metadata": {},
   "source": [
    "# 프로젝트: 더 멋진 번역기 만들기 \n",
    "\n",
    "## Step 1. 데이터 다운로드(로컬 유저용)\n",
    "\n",
    "- 아래 링크에서 ```korean-english-park.train.tar.gz```를 다운받아 한영 병렬 데이터를 확보한다.\n",
    "- [jungyeul/korean-parallel-corpora\n",
    "](https://github.com/jungyeul/korean-parallel-corpora/tree/master/korean-english-news-v1) (이 데이터는 이전 [Seq2seq으로 번역기 만들기] 코스에서 사용한 데이터와 동일하다.)\n",
    "\n",
    "\n",
    "- 터미널을 열어 하단의 명령어를 입력하면 된다.\n",
    "```c\n",
    "$ mkdir -p ~/aiffel/transformer/data\n",
    "$ cd ~/aiffel/transformer/data\n",
    "$ wget https://github.com/jungyeul/korean-parallel-corpora/raw/master/korean-english-news-v1/korean-english-park.train.tar.gz\n",
    "$ gzip -d korean-english-park.train.tar.gz\n",
    "$ tar -xvf korean-english-park.train.tar\n",
    "```\n",
    "\n",
    "- 클라우드 유저의 경우, 우측하단의 Cloud shell을 열어주고, 아래과 같이 공유 디렉토리에 저장된 데이터를 가리키는 심볼릭 링크를 생성해주면 된다.\n",
    "```\n",
    "$ ln -s ~/data ~/aiffel/transformer/data\n",
    "```\n",
    "\n",
    "\n",
    "## Step 2. 데이터 정제 및 토큰화\n",
    "\n",
    "- 1) ```set```데이터형이 **중복을 허용하지 않는다는 것을 활용**해 중복된 데이터를 제거하도록 하자. 데이터의 **병렬 쌍이 흐트러지지 않게 주의**하자. 중복을 제거한 데이터를 ```cleaned_corpus```에 저장하자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "scientific-piano",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4.1\n"
     ]
    }
   ],
   "source": [
    "# 프로젝트에 사용될 라이브러리 import\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.ticker as ticker\n",
    "\n",
    "import time\n",
    "import re\n",
    "import os\n",
    "import io\n",
    "\n",
    "import pandas as pd\n",
    "import urllib.request\n",
    "from konlpy.tag import Okt\n",
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from collections import Counter\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "tight-sugar",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78968\n",
      ">> 중국당국은 탕자산 언색호 제방이 무너지거나 추가 여진이나 지진으로 흙으로 된 둑이 무너져 하류에 있는 지진지역에 갑작스런 홍수피해가 발생할 것을 우려하고 있다. Authorities were concerned that the lake could burst its banks or that another aftershock or earthquake could rupture the earthen dam and cause a sudden flood of water on the communities downstream.\n",
      ">> 그녀는 현재 뉴욕 라가디아 공항에 나가 있습니다. She is live in LaGardia Airport in New York.\n",
      ">> “ 요란한 이틀 간의 전투는 아프간 주둔기지에 대한 무장세력의 선제 공격으로 시작되었습니다. “ A rolling two-day battle began with a militant attack on Afghan outposts.\n",
      ">> 리그 선두를 달리고 있는 바르셀로나는 이번 대회 단 한번도 패배를 기록하지 않고 선두를 지키고 있다. 이날 바르셀로나는 전반 14분 티에리 앙리가 첫 골을 신고했다. Spanish league leaders Barcelona are unbeaten in 18 matches in all competitions and were always on top in Lisbon after Thierry Henry opened the scoring in the 14th minute, brilliantly set up by Lionel Messi.\n",
      ">> 외교통상부 직원들도 구성된 음악 동호회인 MOFAT 밴드가 새로운 드러머로 알렉산더 버시바우 주한미대사를 영입했다. 새롭게 멤버를 영입한 이들은 하이야트 호텔에서 열리는 Parade of Nations에서 첫 공연을 갖는다. The new lineup will be giving its first performance at the Grand Hyatt hotel tomorrow evening as part of the Parade of Nations, a talent show and annual charity gala arranged by the foreign diplomatic community.\n"
     ]
    }
   ],
   "source": [
    "data_dir = os.getenv('HOME')+'/aiffel/transformer/data'\n",
    "kor_path = data_dir+\"/korean-english-park.train.ko\"\n",
    "eng_path = data_dir+\"/korean-english-park.train.en\"\n",
    "\n",
    "# 데이터 정제 및 토큰화\n",
    "def clean_corpus(kor_path, eng_path):\n",
    "    with open(kor_path, \"r\") as f: kor = f.read().splitlines()\n",
    "    with open(eng_path, \"r\") as f: eng = f.read().splitlines()\n",
    "    assert len(kor) == len(eng)\n",
    "\n",
    "    pallel_corpus = list(set(zip(kor,eng)))\n",
    "    print(len(pallel_corpus))\n",
    "\n",
    "    pallel_corpus = pallel_corpus[:30000]\n",
    "\n",
    "    cleaned_corpus_ko = []\n",
    "    cleaned_corpus_en =[]\n",
    "    cleaned_corpus = []\n",
    "\n",
    "    for i in range(len(pallel_corpus)):\n",
    "        cleaned_corpus_ko.append(pallel_corpus[i][0])\n",
    "     \n",
    "    for i in range(len(pallel_corpus)):\n",
    "        cleaned_corpus_en.append(pallel_corpus[i][1])\n",
    "    \n",
    "    for sen_ko,sen_en in zip(cleaned_corpus_ko[:100:20],cleaned_corpus_en[:100:20]): \n",
    "        print(\">>\", sen_ko ,sen_en)    \n",
    "    \n",
    "    return cleaned_corpus\n",
    "\n",
    "cleaned_corpus = clean_corpus(kor_path, eng_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "racial-album",
   "metadata": {},
   "source": [
    "- 2) 정제 함수를 아래 조건을 만족하게 정의하라.\n",
    "\n",
    "> <조건>\n",
    "> 1. 모든 입력을 **소문자로 변환**하라.\n",
    "> 2. **알파벳, 문장부호, 한글**만 남기고 모두 제거하라.\n",
    "> 3. **문장부호 양 옆에 공백을 추가**하라.\n",
    "> 4. 문장 앞뒤의 **불필요한 공백을 제거**하라."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "collective-bermuda",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_sentence(sentence):\n",
    "    \n",
    "    sentence = sentence.lower().strip() # 소문자 변환\n",
    "    sentence = re.sub(r\"([?.!,])\", r\" \\1 \", sentence) \n",
    "    sentence = re.sub(r'[\" \"]+', \" \", sentence)\n",
    "    sentence = re.sub(r\"[^ㄱ-ㅎㅏ-ㅣ가-힣 a-z A-Z?.!,]+\", \" \", sentence)\n",
    "\n",
    "    sentence = sentence.strip() # 문장 앞뒤 공백 제거\n",
    "\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "established-appearance",
   "metadata": {},
   "source": [
    "- 3) 한글 말뭉치 ```kor_corpus```와 영문 말뭉치 ```eng_corpus```를 각각 분리한 후, **정제하여 토큰화를 진행**하자. \n",
    "- **토큰화에는 sentencepiece를 활용**하라.\n",
    "- 첨부된 공식 사이트를 참고해 아래 조건을 만족하는 ```generate_tokenizer()```함수를 정의하라. \n",
    "- 참고 사이트: [google/sentencepiece](https://github.com/google/sentencepiece)\n",
    "- 최종적으로 ```ko_tokenizer```와 ```en_tokenizer```를 얻어라. ```en_tokenizer```에는 ```set_encode_extra_options(\"bos:eos\")``` 함수를 실행해 **타겟 입력이 문장의 시작 토큰과 끝 토큰을 포함할 수 있게** 한다.\n",
    "> <조건>\n",
    "> 1. 단어사전을 매개변수로 받아 **원하는 크기의 사전을 정의**할 수 있게 한다.(기본: 20,000)\n",
    "> 2. 학습 후 저장된 ```model``` 파일을 ```SentencePieceProcessor()``` 클래스레 ```Load()```한 후 반환한다.\n",
    "> 3. **특수 토큰의 인덱스**를 아래와 동일하게 지정한다.\n",
    "> *```<PAD>```: 0/ ```<BOS>```: 1/ ```<EOS>```: 2/ ```<UKN>```: 3*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "meaningful-blackjack",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sentencepiece를 활용하여 학습한 tokenizer를 생성합니다.\n",
    "def generate_tokenizer(corpus,\n",
    "                        vocab_size,\n",
    "                        lang=\"ko\",\n",
    "                        pad_id=0,\n",
    "                        bos_id=1,\n",
    "                        eos_id=2,\n",
    "                        unk_id=3):\n",
    "    # [[YOUR CODE]]\n",
    "\n",
    "    return tokenizer\n",
    "    \n",
    "\n",
    "SRC_VOCAB_SIZE = TGT_VOCAB_SIZE = 20000\n",
    "\n",
    "eng_corpus = []\n",
    "kor_corpus = []\n",
    "\n",
    "for pair in cleaned_corpus:\n",
    "    k, e = pair.split(\"\\t\")\n",
    "\n",
    "    kor_corpus.append(preprocess_sentence(k))\n",
    "    eng_corpus.append(preprocess_sentence(e))\n",
    "\n",
    "ko_tokenizer = generate_tokenizer(kor_corpus, SRC_VOCAB_SIZE, \"ko\")\n",
    "en_tokenizer = generate_tokenizer(eng_corpus, TGT_VOCAB_SIZE, \"en\")\n",
    "en_tokenizer.set_encode_extra_options(\"bos:eos\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "uniform-acoustic",
   "metadata": {},
   "source": [
    "- 4) 토크나이저를 활용해 토큰의 길이가 50 이하인 데이터를 선별하여 ```src_corpus```와 ```tgt_-corpus```를 각각 구축하고, 텐서```enc_train```과 ```dec_train```으로 변환하라.\n",
    "- 모든 데이터를 사용할 경우 학습에 굉장히 오랜 시간이 걸린다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "empirical-emergency",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm_notebook    # Process 과정을 보기 위해\n",
    "\n",
    "src_corpus = []\n",
    "tgt_corpus = []\n",
    "\n",
    "assert len(kor_corpus) == len(eng_corpus)\n",
    "\n",
    "# 토큰의 길이가 50 이하인 문장만 남깁니다. \n",
    "for idx in tqdm_notebook(range(len(kor_corpus))):\n",
    "    # [[YOUR CODE]]\n",
    "\n",
    "# 패딩처리를 완료하여 학습용 데이터를 완성합니다. \n",
    "enc_train = tf.keras.preprocessing.sequence.pad_sequences(src_corpus, padding='post')\n",
    "dec_train = tf.keras.preprocessing.sequence.pad_sequences(tgt_corpus, padding='post')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alive-disclosure",
   "metadata": {},
   "source": [
    "## Step 3. 모델 설계\n",
    "\n",
    "- 오늘 배운 내용을 활용해서 ```Transformer``` 모델을 설계해보아라."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "homeless-deposit",
   "metadata": {},
   "source": [
    "## Step 4. 훈련하기\n",
    "\n",
    "- 앞서 필요한 것을 모두 정의했기에 우리는 훈련만 하면 된다.\n",
    "- 아래 과정을 차근차근 따라가며 모델을 훈련하고, 예문에 대한 멋진 번역을 제출하라.\n",
    "\n",
    "\n",
    "- 1. **2 Layer**를 가지는 ```Transformer```를 선언하라. (하이퍼파라미터는 자유롭게 조절한다.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "transparent-employment",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer = # [[YOUR CODE]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "different-atlanta",
   "metadata": {},
   "source": [
    "- 2. 논문에서 사용한 것과 동일한 **Learning Rate Scheduler**를 선언하고, 이를 포함하는 **Adam Optimizer**를 선언하라. (Optimizer의 파라미터 역시 논문과 동일하게 설정한다.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "white-attack",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = # [[YOUR CODE]]\n",
    "optimizer = # [[YOUR CODE]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "comfortable-pillow",
   "metadata": {},
   "source": [
    "- 3. **Loss 함수를 정의**하라. \n",
    "\n",
    "  Seq2seq 모델에서 사용했건 Loss와 유사하되, **Masking되지 않은 입력의 개수로 Scaling**하는 과정을 추가한다.(트랜스포머가 모든 입력에 대한 Loss를 한 번에 구하기 때문이다.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "divided-adelaide",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "    from_logits=True, reduction='none')\n",
    "\n",
    "def loss_function(real, pred):\n",
    "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "    loss_ = loss_object(real, pred)\n",
    "\n",
    "    # Masking 되지 않은 입력의 개수로 Scaling하는 과정\n",
    "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "    loss_ *= mask\n",
    "\n",
    "    return tf.reduce_sum(loss_)/tf.reduce_sum(mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "progressive-shell",
   "metadata": {},
   "source": [
    "- 4. **```train_step```함수**를 정의하라.\n",
    "\n",
    " **입력 데이터에 알맞은 Mask를 생성**하고, 이를 모델에 전달하여 연산에서 사용할 수 있게 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "julian-simulation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Step 함수 정의\n",
    "\n",
    "@tf.function()\n",
    "def train_step(src, tgt, model, optimizer):\n",
    "    gold = tgt[:, 1:]\n",
    "        \n",
    "    enc_mask, dec_enc_mask, dec_mask = generate_masks(src, tgt)\n",
    "\n",
    "    # 계산된 loss에 tf.GradientTape()를 적용해 학습을 진행합니다.\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions, enc_attns, dec_attns, dec_enc_attns = \\\n",
    "        model(src, tgt, enc_mask, dec_enc_mask, dec_mask)\n",
    "        loss = loss_function(gold, predictions[:, :-1])\n",
    "\n",
    "    # 최종적으로 optimizer.apply_gradients()가 사용됩니다. \n",
    "    # [[YOUR CODE]]\n",
    "    \n",
    "    return loss, enc_attns, dec_attns, dec_enc_attns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "structural-buying",
   "metadata": {},
   "source": [
    "- 5. **학습을 진행**하라.\n",
    "\n",
    " **매 Epoch마다 제시된 예문에 대한 번역을 생성**하고, 멋진 번역이 생성되면 그때의 **하이퍼파라미터와 생성된 번역을 제출**하라.\n",
    " \n",
    " \n",
    "<예문>\n",
    "```c\n",
    "1. 오바마는 대통령이다.\n",
    "2. 시민들은 도시 속에 산다.\n",
    "3. 커피는 필요 없다.\n",
    "4. 일곱 명의 사망자가 발생했다.\n",
    "```\n",
    "\n",
    "\n",
    "<결과(output)>\n",
    "```c\n",
    "Translations\n",
    "> 1. obama is the president elect .\n",
    "> 2. they are in the city .\n",
    "> 3. they don t need to be a lot of drink .\n",
    "> 4. seven other people have been killed in the attacks .\n",
    "\n",
    "Hyperparameters\n",
    "> n_layers: 2\n",
    "> d_model: 512\n",
    "> n_heads: 8\n",
    "> d_ff: 2048\n",
    "> dropout: 0.3\n",
    "\n",
    "Training Parameters\n",
    "> Warmup Steps: 4000\n",
    "> Batch Size: 64\n",
    "> Epoch At: 5\n",
    "```\n",
    "\n",
    "\n",
    "- 번역 생성에는 아래 소스를 사용하길 바란다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "diverse-understanding",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attention 시각화 함수\n",
    "\n",
    "def visualize_attention(src, tgt, enc_attns, dec_attns, dec_enc_attns):\n",
    "    def draw(data, ax, x=\"auto\", y=\"auto\"):\n",
    "        import seaborn\n",
    "        seaborn.heatmap(data, \n",
    "                        square=True,\n",
    "                        vmin=0.0, vmax=1.0, \n",
    "                        cbar=False, ax=ax,\n",
    "                        xticklabels=x,\n",
    "                        yticklabels=y)\n",
    "        \n",
    "    for layer in range(0, 2, 1):\n",
    "        fig, axs = plt.subplots(1, 4, figsize=(20, 10))\n",
    "        print(\"Encoder Layer\", layer + 1)\n",
    "        for h in range(4):\n",
    "            draw(enc_attns[layer][0, h, :len(src), :len(src)], axs[h], src, src)\n",
    "        plt.show()\n",
    "        \n",
    "    for layer in range(0, 2, 1):\n",
    "        fig, axs = plt.subplots(1, 4, figsize=(20, 10))\n",
    "        print(\"Decoder Self Layer\", layer+1)\n",
    "        for h in range(4):\n",
    "            draw(dec_attns[layer][0, h, :len(tgt), :len(tgt)], axs[h], tgt, tgt)\n",
    "        plt.show()\n",
    "\n",
    "        print(\"Decoder Src Layer\", layer+1)\n",
    "        fig, axs = plt.subplots(1, 4, figsize=(20, 10))\n",
    "        for h in range(4):\n",
    "            draw(dec_enc_attns[layer][0, h, :len(tgt), :len(src)], axs[h], src, tgt)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "essential-prison",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 번역 생성 함수\n",
    "\n",
    "def evaluate(sentence, model, src_tokenizer, tgt_tokenizer):\n",
    "    sentence = preprocess_sentence(sentence)\n",
    "\n",
    "    pieces = src_tokenizer.encode_as_pieces(sentence)\n",
    "    tokens = src_tokenizer.encode_as_ids(sentence)\n",
    "\n",
    "    _input = tf.keras.preprocessing.sequence.pad_sequences([tokens],\n",
    "                                                           maxlen=enc_train.shape[-1],\n",
    "                                                           padding='post')\n",
    "    \n",
    "    ids = []\n",
    "    output = tf.expand_dims([tgt_tokenizer.bos_id()], 0)\n",
    "    for i in range(dec_train.shape[-1]):\n",
    "        enc_padding_mask, combined_mask, dec_padding_mask = \\\n",
    "        generate_masks(_input, output)\n",
    "\n",
    "        predictions, enc_attns, dec_attns, dec_enc_attns =\\\n",
    "        model(_input, \n",
    "              output,\n",
    "              enc_padding_mask,\n",
    "              combined_mask,\n",
    "              dec_padding_mask)\n",
    "\n",
    "        predicted_id = \\\n",
    "        tf.argmax(tf.math.softmax(predictions, axis=-1)[0, -1]).numpy().item()\n",
    "\n",
    "        if tgt_tokenizer.eos_id() == predicted_id:\n",
    "            result = tgt_tokenizer.decode_ids(ids)\n",
    "            return pieces, result, enc_attns, dec_attns, dec_enc_attns\n",
    "\n",
    "        ids.append(predicted_id)\n",
    "        output = tf.concat([output, tf.expand_dims([predicted_id], 0)], axis=-1)\n",
    "\n",
    "    result = tgt_tokenizer.decode_ids(ids)\n",
    "\n",
    "    return pieces, result, enc_attns, dec_attns, dec_enc_attns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "driven-korea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 번역 생성 및 Attention 시각화 결합\n",
    "\n",
    "def translate(sentence, model, src_tokenizer, tgt_tokenizer, plot_attention=False):\n",
    "    pieces, result, enc_attns, dec_attns, dec_enc_attns = \\\n",
    "    evaluate(sentence, model, src_tokenizer, tgt_tokenizer)\n",
    "    \n",
    "    print('Input: %s' % (sentence))\n",
    "    print('Predicted translation: {}'.format(result))\n",
    "\n",
    "    if plot_attention:\n",
    "        visualize_attention(pieces, result.split(), enc_attns, dec_attns, dec_enc_attns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stuffed-january",
   "metadata": {},
   "source": [
    "- ```translate()``` 함수의 ```plot_attention``` 변수를 ```True```로 주면 **번역 결과에 대한 Attention Map을 시각화 해볼 수 있다.\n",
    "\n",
    "\n",
    "- 이번 프로젝트에서 제시한 예문은 [Seq2seq으로 번역기 만들기]의 예문과 동일하다. Seq2seq와 Transformer로 만든 2개의 번역기의 성능을 하이퍼파라미터를 조정하는 등 다양한 방식으로 연구하면 학습에 도움이 될 것이다.\n",
    "\n",
    "\n",
    "- 마지막으로 학습 전과정을 구현한 코드를 첨부하니 구현 과정에 참여하길 바란다.\n",
    "```c\n",
    "# 학습\n",
    "\n",
    "from tqdm import tqdm_notebook \n",
    "\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 20\n",
    "\n",
    "examples = [\n",
    "            \"오바마는 대통령이다.\",\n",
    "            \"시민들은 도시 속에 산다.\",\n",
    "            \"커피는 필요 없다.\",\n",
    "            \"일곱 명의 사망자가 발생했다.\"\n",
    "]\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    total_loss = 0\n",
    "\n",
    "    idx_list = list(range(0, enc_train.shape[0], BATCH_SIZE))\n",
    "    random.shuffle(idx_list)\n",
    "    t = tqdm_notebook(idx_list)\n",
    "\n",
    "    for (batch, idx) in enumerate(t):\n",
    "        batch_loss, enc_attns, dec_attns, dec_enc_attns = \\\n",
    "        train_step(enc_train[idx:idx+BATCH_SIZE],\n",
    "                    dec_train[idx:idx+BATCH_SIZE],\n",
    "                    transformer,\n",
    "                    optimizer)\n",
    "\n",
    "        total_loss += batch_loss\n",
    "\n",
    "        t.set_description_str('Epoch %2d' % (epoch + 1))\n",
    "        t.set_postfix_str('Loss %.4f' % (total_loss.numpy() / (batch + 1)))\n",
    "\n",
    "    for example in examples:\n",
    "        translate(example, transformer, ko_tokenizer, en_tokenizer)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "liable-teaching",
   "metadata": {},
   "source": [
    "****\n",
    "# 루브릭 평가\n",
    "\n",
    "|평가문항|상세기준|\n",
    "|:-----|:-----|\n",
    "|1. 번역기 모델 학습에 필요한 텍스트 데이터 전처리가 잘 이루어졌다.|데이터 정제, SentencePiece를 활용한 토큰화 및 데이터셋 구축의 과정이 지시대로 진행되었다.|\n",
    "|2. Transformer 번역기 모델이 정상적으로 구동된다.|Transformer 모델의 학습과 추론 과정이 정상적으로 진행되어, 한-영 번역기능이 정상 동작한다.|\n",
    "|3. 테스트 결과 의미가 통하는 수준의 번역문이 생성되었다.|제시된 문장에 대한 그럴듯한 영어 번역문이 생성되며, 시각화된 Attention Map으로 결과를 뒷받침한다.|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "progressive-wholesale",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "colored-training",
   "metadata": {},
   "source": [
    "# 회고"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "empty-terry",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aiffel",
   "language": "python",
   "name": "aiffel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
